=======================================================================

bedingte Wahrscheinlichkeiten


Wahrscheinlich P(A * B) = Ereignis A und B sind erfuellt

P(A n B)/P(A * B) = P(A) * P(B)
=> Unabhaengigkeit


Bedingte Wahrscheinlichekeiten P(U|R)
= Wahrscheinlikeit von Ereignis U bedingt Ereigtnis R

P(U|R) = P(U n R)/ P(R)

Wenn Beingung unabhaengig von Ereignis, dann gilt:
P(A|B) = P(A) <=> A und B unabhaengig


Forlem totale Wahscheinlichkeit
P(A n B) = P(B) * P(A|B)

--> Vollstaendiges Ereignissystem
-> Bi n Bj = {}, UBi = Omega

Markov-Ungl.
x>=0 nicht negative Zufallsvariable
a >= 0

P(x >= a) <= E[x]/a


Erinnere: Lin. des Erwartungswertes
E[x+y] = E[x] + E[y]
E[x * lambda] = E[x] * lambda
E[x+lambda] = E[x] + lambda


bhaengige Zufallsvariablen
P(x=a, y=b) = P(x=a) * P(y=b)
% Komma sagt, dass beide Ereignisse eintreten


Geometrische Verteilung:
% Wie gross ist Wahrscheinlichkeit, dass k Events vergehen, bis Ereignis eintritt

P(x=k) = (1-p)^k-1 * p
E[x] = 1/p

Satz vom totalen Erwartungswert:
E[x] = E[x|Bi] * P(Bi) + E[x|B2] * P(B2)

Bedinger Erwartungswert:
E[x|B] = Sum(i elem. |R) i * P(x=r|B)


Varianz:
% Durchschnittlicher Abstand vom Erwartungswert
V[x] = E[ (x-E[x])^2 ] = E[x^2] - (E[x])^2
% nochmal nach praktischer Rechnung schauen


Chebychev Ungleichung:
x >= 0
P[x x>= 1] <= E[X]/a <== Markov
P(|x=E[x]| >= t) <= V[x]/t^2

Chernoff Ungl.:
%bilt nur fuer unabhaengige bin. Variablen
x1,..,xk unabhaengige bin. Zufallsvar.
P(Xi = 1) = pi
E[x] = sum(i=1, k) E[x1] = Sum(i=1, k) pi
% hier haessliche Gleichung einsetzen
% wahrscheinlichkeit nach oben abzuweichen:
P(x >= (1+beta( * E[x]) <= e^-(E[x] * beta^2 /3) fuer alle beta>0
% wahrscheinlichkeit nach unten abzugleichen (?):
P(x >= (1-beta( * E[x]) <= e^-(E[x] * beta^2 /2) fuer alle beta>0
Beide Gleichungen lernen!!!
